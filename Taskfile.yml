# yaml-language-server: $schema=https://taskfile.dev/schema.json

version: '3'

env:
  AWS_PROFILE: lab

tasks:
  default:
    silent: true
    cmds:
      - task -l

  deploy:
    desc: Deploy lab (terraform + helm + ingress)
    silent: true
    cmds:
      - task: tf-apply
      - task: kubeconfig
      - task: wait-for-nodes
      - task: helm-install-lbc
      - task: helm-install-argocd
      - task: apply-argocd-ingress
      - task: apply-grafana-ingress

  destroy:
    desc: Destroy lab
    silent: true
    cmds:
      - task: kubeconfig
      - task: delete-ingress
      - task: drain-and-destroy-nodes
      - task: terraform-destroy
      - task: cleanup-orphaned-enis

  plan:
    desc: Show terraform plan
    dir: terraform
    silent: true
    cmds:
      - terraform init -backend-config=backend.hcl
      - terraform plan

  kubeconfig:
    desc: Add the cluster to ~/.kube/config
    silent: true
    cmds:
      - aws eks update-kubeconfig --name k8s-lab --alias k8s-lab --region us-east-1

  argocd-pf:
    desc: Setup local port forwarding to the ArgoCD pod
    silent: true
    cmds:
      - echo http://127.0.0.1:8080
      - kubectl port-forward -n argocd svc/argo-cd-argocd-server 8080:443 > /dev/null

  argocd-password:
    desc: Get the default admin password for ArgoCD
    silent: true
    cmds:
      - kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d

  grafana-password:
    desc: Get the default admin password for Grafana
    silent: true
    cmds:
      - kubectl get secret -n monitoring kube-prometheus-stack-grafana -o jsonpath="{.data.admin-password}" | base64 -d

  alb_dns:
    desc: Print out the ALB DNS name
    silent: true
    cmds:
      - echo "http://$(aws elbv2 describe-load-balancers --query 'LoadBalancers[*].DNSName' --output text | grep k8s-lab)"


  tf-apply:
    dir: terraform
    silent: true
    cmds:
      - terraform init -backend-config=backend.hcl
      - terraform apply -auto-approve

  wait-for-nodes:
    silent: true
    cmds:
      - kubectl wait --for=condition=Ready nodes --all --timeout=300s

  helm-install-lbc:
    silent: true
    cmds:
      - helm repo add eks https://aws.github.io/eks-charts
      - helm repo update eks
      - |
        helm upgrade --install aws-load-balancer-controller eks/aws-load-balancer-controller \
          -n kube-system \
          --set clusterName=k8s-lab \
          --set serviceAccount.create=true \
          --set serviceAccount.name=aws-load-balancer-controller \
          --set "serviceAccount.annotations.eks\.amazonaws\.com/role-arn=$(terraform -chdir=terraform output -raw aws_lbc_role_arn)" \
          --set vpcId=$(terraform -chdir=terraform output -raw vpc_id) \
          --wait

  helm-install-argocd:
    silent: true
    cmds:
      - helm repo add argo https://argoproj.github.io/argo-helm
      - helm repo update argo
      - |
        helm upgrade --install argo-cd argo/argo-cd \
          -n argocd \
          --create-namespace \
          --set server.service.type=ClusterIP \
          --set server.ingress.enabled=false \
          --set "server.extraArgs={--insecure,--basehref=/argocd,--rootpath=/argocd}" \
          --wait \
          --timeout 10m

  apply-argocd-ingress:
    silent: true
    cmds:
      - ALB_SECURITY_GROUP_ID=$(terraform -chdir=terraform output -raw alb_security_group_id) envsubst < manifests/argocd-ingress.yaml | kubectl apply -f -

  apply-grafana-ingress:
    silent: true
    cmds:
      - kubectl create namespace monitoring
      - ALB_SECURITY_GROUP_ID=$(terraform -chdir=terraform output -raw alb_security_group_id) envsubst < manifests/grafana-ingress.yaml | kubectl apply -f -

  delete-ingress:
    silent: true
    cmds:
      - kubectl delete ingress -n argocd argocd-server --ignore-not-found=true
      - kubectl delete ingress -n monitoring grafana --ignore-not-found=true
      - echo "Waiting for ALB resources to be deleted..."
      - sleep 300

  drain-and-destroy-nodes:
    silent: true
    cmds:
      - kubectl get nodes -o name | xargs -n1 kubectl drain --ignore-daemonsets --delete-emptydir-data --force --grace-period=60 --disable-eviction || true
      - echo "Nodes drained, waiting for VPC CNI cleanup..."
      - sleep 90
      - terraform -chdir=terraform destroy -target='module.k8s_lab.module.eks[0].module.eks.module.eks_managed_node_group["default"]' -auto-approve

  terraform-destroy:
    dir: terraform
    silent: true
    cmds:
      - terraform destroy -auto-approve

  cleanup-orphaned-enis:
    silent: true
    cmds:
      - aws ec2 describe-network-interfaces --filters Name=tag:cluster.k8s.amazonaws.com/name,Values=k8s-lab --query NetworkInterfaces[*].NetworkInterfaceId --output text | xargs -r -n1 aws ec2 delete-network-interface --network-interface-id
